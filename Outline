Project Outline: Cancer Marker Analysis from Nanoscopic-Tissue Images with Deep Tech
Domain and Techniques
Domain: Machine Learning, with a focus on Deep Learning and Image Recognition.
Techniques: Utilizes Deep Convolutional Neural Network (CNN), Transfer Learning, with specific implementation via AutoML and NASNetMobile for advanced image classification tasks.
Description and Impact on Sustainable Development Goals (Criteria 1)
Problem Statement: Early detection of cancer through histopathologic analysis of tissue images represents a critical challenge in healthcare, directly impacting Sustainable Development Goal 3: Good Health and Well-being.
Solution Overview: The project leverages Google's AutoML technology (NASNet) to identify cancer markers in microscopic tissue images. By achieving high accuracy in identifying these markers, the solution can significantly contribute to early cancer detection, thereby improving patient outcomes and reducing healthcare costs.
Scalability and Impact: With a 90.21% testing accuracy on a substantial dataset, this approach demonstrates potential for real-world application and scalability across different types of cancer and diagnostic settings.
Innovation and Creativity (Criteria 2)
Innovative Approach: The project employs a novel combination of AutoML for model optimization and NASNetMobile for efficient, accurate analysis of histopathologic images. This unique approach showcases creativity in applying generative AI to solve a critical healthcare problem.
Generative AI Use: Through the creative use of generative AI, this project pushes the boundaries of what's possible in medical image analysis, setting a new standard for the application of AI in healthcare.
Technical Quality (Criteria 3)
Architecture and Tech Stack: The solution's architecture is meticulously designed to leverage the strengths of generative AI, utilizing a combination of AutoML for model selection and optimization, and NASNetMobile for efficient processing of large-scale image datasets.
Cohesive Design: All components of the solution, from image preprocessing to classification and result interpretation, integrate seamlessly to create a cohesive, robust system for cancer marker analysis.
Working Demo (Criteria 4)
Demo Highlights: The project includes a working demo that clearly showcases the system's ability to classify histopathologic images with high accuracy. The demo runs smoothly, presenting the main features and capabilities of the solution with clarity and precision.
Presentation (Criteria 5)
Communication and Engagement: The presentation is designed to effectively communicate the problem, solution, and technical details of the project. It engages the audience with clear, professional communication, demonstrating a deep understanding of the topic and the innovative use of AI in addressing it.
Alignment with Prize Categories
Best AI Hack: The project stands out as a prime candidate for the Best AI Hack, given its innovative use of generative AI in addressing a critical healthcare challenge.
Best AI in Healthcare Hack: As a direct application to healthcare, this project is a strong contender for the Best AI in Healthcare Hack, showcasing the potential of AI to revolutionize cancer diagnosis.
Best AI in Climate Change & Sustainability: While primarily focused on healthcare, the project indirectly contributes to sustainability by improving healthcare outcomes and efficiency, potentially aligning with broader sustainability goals.
Dataset and Model Performance
Detailed information on the dataset, model training parameters, and performance metrics are provided to demonstrate the scientific rigor and effectiveness of the solution.
Tools and Libraries
Utilizes Python, Anaconda, and libraries such as Keras and TensorFlow, highlighting the technical depth and the advanced tools employed in the development of the solution.












### Cancer Marker Analysis from Nanoscopic-Tissue Images with Deep Tech (AI ML, Neural Network) 
<pre>
Domain             : Machine Learning
Sub-Domain         : Deep Learning, Image Recognition
Techniques         : Deep Convolutional Neural Network, Transfer Learning, ImageNet, Auto ML, NASNetMobile
Application        : Image Recognition, Image Classification, Medical Imaging
</pre>

### Description
<pre>
1. used autoML (Google's "NASNet") to identify cancer from microscopic tissue photos (histopathologic).
2. To get the final output prediction for training, concatenate global pooling (max, average), dropout, and dense layers to the output layer.
3. Achieved a 90.21% testing accuracy and a 0.45 loss on a cancer imaging dataset with over 250K images (7.5GB+).

#### Dataset
<pre>
Dataset Name     : Histopathologic Cancer Detection
Dataset Link     : <a href=https://www.kaggle.com/c/histopathologic-cancer-detection>Histopathologic Cancer Detection (Kaggle)</a>
                 : <a href=https://github.com/basveeling/pcam>PatchCamelyon (PCam) (GitHub)</a>
                 : <a href=https://camelyon16.grand-challenge.org/Data/>CAMELYON16 challenge Dataset (Original Dataset)</a>
                 
Original Paper   : <a href=https://jamanetwork.com/journals/jama/fullarticle/2665774>Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer </a> 
                   Authors: Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes van Diest 
                   JAMA (The Journal of the American Medical Association)
                   <cite>Ehteshami Bejnordi B, Veta M, Johannes van Diest P, et al. Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA. 2017;318(22):2199â€“2210. doi:10.1001/jama.2017.14585</cite>
</pre>

### Dataset Details
<pre>
Dataset Name            : Cancer Detection
Number of Class         : 2
</pre>

| Dataset Subtype | Number of Image | Size of Images (GB/Gigabyte) |
| :-------------- | --------------: | ---------------------------: |
| **Total**       | 234,055         | 6.82 GB                      |
| **Training**    | 135,008         | 4.93 GB                      |
| **Validation**  | 54,005          | 2.16 GB                      |
| **Testing**     | 55,004          | 1.18 GB                      |


### Model and Training Prameters
| Current Parameters   | Value                                                       |
| :------------------- | ----------------------------------------------------------: |
| **Base Model**       | NashNetLarge                                                |
| **Optimizers**       | Adam                                                        |
| **Loss Function**    | Categorical Crossentropy                                    |
| **Learning Rate**    | 0.0002                                                      |
| **Batch Size**       | 32                                                          |                                     
| **Number of Epochs** | 2                                                           |
| **Training Time**    | 6.5 hour (270 min)                                          |


### Model Performance Metrics (Prediction/ Recognition / Classification)
| Dataset              | Training       | Validation    | Test      |                                 
| :------------------- | -------------: | ------------: | --------: |
| **Accuracy**         | 92.42%         | 93.62%        | 90.21%    |
| **Loss**             | 0.22           | 0.25          | 0.40     |
| **Precision**        | ---            | ---           | 86.87%    |
| **Recall**           | ---            | ---           | 88.09%    |
| **Roc-Auc**          | ---            | ---           | 92.76%    |


### Other Experimented Model and Training Prameters
| Parameters (Experimented) | Value                                                  |
| :------------------------ | -----------------------------------------------------: |
| **Base Models**           | NashNet(NashNetLarge, NashNetMobile), InceptionV3      |
| **Optimizers**            | Adam, SGD                                              |
| **Loss Function**         | Categorical Crossentropy, Binary Crossentropy          |
| **Learning Rate**         | 0.0001, 0.00001, 0.000001, 0.0000001                   |
| **Batch Size**            | 32, 64, 128, 256, 512                                  |                                     
| **Number of Epochs**      | 2, 4, 6, 10, 30, 50, 100                               |
| **Training Time**         | 4.5 hour (270 min), 1 day (24 hours), 2 days (24 hours)|


##### Sample Output: 
<kbd>
<img src=https://github.com/siddhartha18pahari/GENAI/blob/main/CANCER1.png
</kbd>


#### Tools / Libraries
<pre>
Languages               : Python
Tools/IDE               : Anaconda
Libraries               : Keras, TensorFlow, Inception, ImageNet
</pre>

